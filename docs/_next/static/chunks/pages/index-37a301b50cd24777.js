(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[405],{5301:function(e,t,i){(window.__NEXT_P=window.__NEXT_P||[]).push(["/",function(){return i(322)}])},322:function(e,t,i){"use strict";i.r(t),i.d(t,{default:function(){return S}});var n=i(5893),r=i(8527),o=i(1664),s=i.n(o),a={1:"VGG Group, Oxford University"},l=[{name:"Luke Melas-Kyriazi",institutions:[1],url:"https://github.com/lukemelas/"},{name:"Christian Rupprecht",institutions:[1],url:"https://chrirupp.github.io/"},{name:"Andrea Vedaldi",institutions:[1],url:"https://www.robots.ox.ac.uk/~vedaldi/"}],c="#",u="https://github.com/lukemelas/projection-conditioned-point-cloud-diffusion",p=function(){return(0,n.jsxs)(r.X6,{fontWeight:"light",fontSize:"3xl",pt:"3rem",maxW:"60rem",textAlign:"center",children:[(0,n.jsxs)(r.xv,{fontWeight:"bold",as:"span",children:["PC",(0,n.jsx)("sup",{children:"2"})]}),": Projection-Conditioned Point Cloud Diffusion for Single-Image 3D Reconstruction"]})},d=function(){return(0,n.jsxs)(r.W2,{maxW:"60rem",children:[(0,n.jsx)(r.Eq,{justify:"center",pt:"1rem",fontSize:"xl",children:l.map((function(e){return(0,n.jsxs)(r.xu,{pl:"1rem",pr:"1rem",children:[(0,n.jsx)(s(),{href:e.url,passHref:!0,children:(0,n.jsx)(r.rU,{children:e.name})}),(0,n.jsxs)("sup",{children:[" ",e.institutions.toString()]})]},e.name)}))},"authors"),(0,n.jsx)(r.Eq,{justify:"center",pt:"1rem",children:Object.entries(a).map((function(e){return(0,n.jsxs)(r.xu,{children:[(0,n.jsxs)("sup",{children:[e[0],"  "]}),e[1]]},e[0])}))},"institutions")]})},h=i(949);function m(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}var f=function(e){var t=(0,h.If)().colorMode;return(0,n.jsx)(r.kC,function(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{},n=Object.keys(i);"function"===typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(i).filter((function(e){return Object.getOwnPropertyDescriptor(i,e).enumerable})))),n.forEach((function(t){m(e,t,i[t])}))}return e}({direction:"column",alignItems:"center",justifyContent:"flex-start",bg:{light:"white",dark:"gray.900"}[t],color:{light:"black",dark:"white"}[t]},e))},g=i(9762),x=i(9697),j=function(){var e=(0,h.If)(),t=e.colorMode,i=e.toggleColorMode,o="dark"===t;return(0,n.jsx)(n.Fragment,{children:(0,n.jsxs)(r.Kq,{direction:"row",position:"fixed",top:"1rem",right:"1rem",children:[(0,n.jsx)(g.lX,{htmlFor:"dark-mode-switch",mt:"-3px",opacity:"0.3",children:o?"Dark":"Light"}),(0,n.jsx)(x.r,{color:"green",isChecked:o,onChange:i})]})})},b=i(6723),w=i(8193),y=i(1649),v=function(){return(0,n.jsxs)(r.Kq,{direction:"row",spacing:4,pt:"2rem",pb:"2rem",children:[(0,n.jsx)(s(),{href:c,passHref:!0,children:(0,n.jsx)(b.zx,{leftIcon:(0,n.jsx)(y.e3_,{size:"25px"}),colorScheme:"teal",variant:"outline",children:"Paper"})}),(0,n.jsx)(s(),{href:u,passHref:!0,children:(0,n.jsx)(b.zx,{leftIcon:(0,n.jsx)(w.idJ,{size:"25px"}),colorScheme:"teal",variant:"solid",children:"GitHub"})})]})};function k(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}var C=function(e){return(0,n.jsx)(r.kC,function(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{},n=Object.keys(i);"function"===typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(i).filter((function(e){return Object.getOwnPropertyDescriptor(i,e).enumerable})))),n.forEach((function(t){k(e,t,i[t])}))}return e}({as:"footer",py:"4rem"},e))},P=i(3454),S=function(){return(0,n.jsxs)(f,{children:[(0,n.jsx)(p,{}),(0,n.jsx)(d,{}),(0,n.jsx)(v,{}),(0,n.jsx)(f,{w:"90vw",h:"50.6vw",maxW:"50rem",maxH:"25rem",mb:"3rem",children:(0,n.jsx)("iframe",{width:"100%",height:"100%",src:"https://www.youtube.com/embed/kAkwpsT1pRA",title:"Video",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0})}),(0,n.jsxs)(f,{w:"100%",maxW:"60rem",alignItems:"left",pl:"1rem",pr:"1rem",children:[(0,n.jsx)(r.X6,{fontWeight:"light",fontSize:"2xl",pb:"1rem",children:"Abstract"}),(0,n.jsx)(r.xv,{pb:"2rem",children:"Reconstructing the 3D shape of an object from a single RGB image is a long-standing and highly challenging problem in computer vision. In this paper, we propose a novel method for single-image 3D reconstruction which generates a sparse point cloud via a conditional denoising diffusion process. Our method takes as input a single RGB image along with its camera pose and gradually denoises a set of 3D points, whose positions are initially sampled randomly from a three-dimensional Gaussian distribution, into the shape of an object. The key to our method is a geometrically-consistent conditioning process which we call projection conditioning: at each step in the diffusion process, we project local image features onto the partially-denoised point cloud from the given camera pose. This projection conditioning process enables us to generate high-resolution sparse geometries that are well-aligned with the input image, and can additionally be used to predict point colors after shape reconstruction. Moreover, due to the probabilistic nature of the diffusion process, our method is naturally capable of generating multiple different shapes consistent with a single input image. In contrast to prior work, our approach not only performs well on synthetic benchmarks, but also gives large qualitative improvements on complex real-world data."}),(0,n.jsx)(r.X6,{fontWeight:"light",fontSize:"2xl",pb:"1rem",children:"Examples"}),(0,n.jsx)("img",{src:"".concat(P.env.BASE_PATH||"","/images/method-diagram-v3.png")}),(0,n.jsxs)(r.xv,{margin:"auto",pt:"0.5rem",pb:"0.5rem",fontSize:"small",paddingBottom:"2rem",children:[(0,n.jsx)(r.xv,{fontWeight:"bold",as:"span",children:"Method Diagram."})," ",(0,n.jsxs)(r.xv,{fontWeight:"bold",as:"span",children:["PC",(0,n.jsx)("sup",{children:"2"})]})," reconstructs a colored point cloud from a single input image along with its camera pose. The method contains two sub-parts, both of which utilize our model projection conditioning method. First, we gradually denoise a set of points into the shape of an object. At each step in the diffusion process, we project image features onto the partially-denoised point cloud from the given camera pose, augmenting each point with a set of neural features. This step makes the diffusion process conditional on the image in a geometrically-consistent manner, enabling high-quality shape reconstruction. Second, we predict the color of each point using a model based on the same projection procedure. Hi"]}),(0,n.jsx)("img",{src:"".concat(P.env.BASE_PATH||"","/images/splash-figure.png")}),(0,n.jsxs)(r.xv,{margin:"auto",pt:"0.5rem",pb:"0.5rem",fontSize:"small",paddingBottom:"2rem",children:[(0,n.jsxs)(r.xv,{fontWeight:"bold",as:"span",children:["PC",(0,n.jsx)("sup",{children:"2"})]})," performs single-image 3D point cloud reconstruction by gradually diffusing an initially random point cloud to align the with input image. It has been trained through simple, sparse COLMAP supervision from videos."]}),(0,n.jsx)("img",{src:"".concat(P.env.BASE_PATH||"","/images/results-figure-v3.png")}),(0,n.jsx)(r.xv,{margin:"auto",pt:"0.5rem",pb:"0.5rem",fontSize:"small",children:"Examples on three real-world categories from Co3D: toytrucks, teddy bears, and hydrants."}),(0,n.jsx)(r.X6,{fontWeight:"light",fontSize:"2xl",pt:"2rem",pb:"1rem",children:"Citation"}),(0,n.jsxs)(r.EK,{p:"0.5rem",borderRadius:"5px",overflow:"scroll",whiteSpace:"nowrap",children:["  ","@inproceedings{ ",(0,n.jsx)("br",{}),"\xa0\xa0\xa0\xa0","melaskyriazi2023projection",", ",(0,n.jsx)("br",{}),"\xa0\xa0\xa0\xa0title={","PC2: Projection-Conditioned Point Cloud Diffusion for Single-Image 3D Reconstruction","} ",(0,n.jsx)("br",{}),"\xa0\xa0\xa0\xa0author={","Luke Melas-Kyriazi and Christian Rupprecht and Andrea Vedaldi","} ",(0,n.jsx)("br",{}),"\xa0\xa0\xa0\xa0year={","2023","} ",(0,n.jsx)("br",{}),"\xa0\xa0\xa0\xa0booktitle={","Arxiv","} ",(0,n.jsx)("br",{}),"}"]}),(0,n.jsx)(r.X6,{fontWeight:"light",fontSize:"2xl",pt:"2rem",pb:"1rem",children:"Acknowledgements"}),(0,n.jsx)(r.xv,{children:"L.M.K. is supported by the Rhodes Trust. A.V. and C.R. are supported by ERC-UNION-CoG-101001212. C.R. is also supported by VisualAI EP/T028572/1."})]}),(0,n.jsx)(j,{}),(0,n.jsx)(C,{children:(0,n.jsx)(r.xv,{})})]})}}},function(e){e.O(0,[866,617,330,774,888,179],(function(){return t=5301,e(e.s=t);var t}));var t=e.O();_N_E=t}]);